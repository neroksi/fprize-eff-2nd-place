{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3357ba4",
   "metadata": {
    "papermill": {
     "duration": 0.014434,
     "end_time": "2022-08-22T03:10:23.113003",
     "exception": false,
     "start_time": "2022-08-22T03:10:23.098569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* v01 : 999_v1_02 : 99_v1_02_22(oof=0.5814, LB=0.575), use discourse_type as feature, catboost, oof=0.5805, LB=0.573  \n",
    "  \n",
    "  --- [BUG] order of 1st level predictions are not correct ... ---  \n",
    "  --- This is corrected below ---  \n",
    "  \n",
    "* v02 : 999_v1_02 : 99_v1_02_22(oof=0.5814, LB=0.575), use discourse_type as feature, catboost, oof=0.5805, LB=0.572  \n",
    "* v03 : 999_v1_05 : 99_v1_02_27(oof=0.5803, LB=0.575), use discourse_type as feature, catboost, oof=0.5796, LB=0.572  \n",
    "* v04 : 999_v1_06 : 99_v1_02_28(oof=0.5805, LB=?), use discourse_type as feature, catboost, oof=0.5786, LB=0.573  \n",
    "* v06 : 999_v1_15 : 99_v1_04_01(oof=0.5797, LB=), use discourse_type as feature, catboost, oof=0.5788, LB=0.571  \n",
    "* v07 : 999_v1_15+all data : 99_v1_04_01(oof=0.5797, LB=), use discourse_type as feature, catboost, oof=0.5788 | replace 18_v2_01 with 24_v2_01, LB=0.570  \n",
    "* v08 : 999_v1_16+all data : 99_v1_04_02(oof=0.5798, LB=), use discourse_type as feature, catboost, oof=0.5789 | replace 18_v2_01 with 24_v2_01(deberta-large), LB=0.570  \n",
    "  \n",
    "  \n",
    "  --- legit pl ---  \n",
    "  \n",
    "* [BUG] v10 : 999_v1_22 : 29_v2_01(oof=0.5870, LB=), use Shujun's features, catboost, oof=0.5840, LB=0.570  \n",
    "* [BUG] v11 : 999_v1_22 : 29_v2_01(oof=0.5870, LB=), use Shujun's features, catboost, oof=0.5840, LB=0.570  \n",
    "  \n",
    "  \n",
    "  --- bug corrected (take average for prob_seq) ---  \n",
    "* v13 : 999_v1_22 : 29_v2_01(oof=0.5870, LB=), use Shujun's features, catboost, oof=0.5840, LB=  \n",
    "* v14 : 999_v1_22 with avg(5x5) : 29_v2_01(oof=0.5870, LB=), use Shujun's features, catboost, oof=0.5840, LB=0.568  \n",
    "* v15 : 99_v1_06_02 with avg(5x5) : 999_v1_06_01(single stacking, deberta-large, seed100) + 999_v1_06_02(single stacking, deberta-v3-large, seed100), oof=0.5777, LB=0.564  \n",
    "* v16 : 99_v1_06_06 : 999_v1_22(single stacking, deberta-large, seed100) + 999_v1_23(single stacking, deberta-v3-large, seed100) + 999_v1_25(single stacking, deberta-xlarge, seed100), oof=0.5756, avg(5x5) LB=  \n",
    "* v17 : 99_v1_06_07 : 999_v1_22(single stacking, deberta-large, seed100) cat&lgb + 999_v1_23(single stacking, deberta-v3-large, seed100) cat&lgb + 999_v1_25(single stacking, deberta-xlarge, seed100) cat&lgb, oof=0.5751, avg(5x5xnum_models) LB=0.564  \n",
    "  \n",
    "  \n",
    "  --- 2nd round pl ---  \n",
    "* v18 : 99_v1_06_10 : 999_v1_26(single stacking, deberta-large, seed100) + 999_v1_27(single stacking, deberta-v3-large, seed100), oof=0.5787, avg(5x5xnum_models) LB=0.565  \n",
    "  \n",
    "  \n",
    "  --- all data ---  \n",
    "* v19 : 999_v1_22(replace by all_data 32_v2_01(deberta-large), SWA(epoch1,2,3)) with avg(5x5) : 29_v2_01(oof=0.5870, LB=), use Shujun's features, catboost, LB=0.566  \n",
    "* v21 : 999_v1_22(replace by all_data 32_v2_01(deberta-large), SWA(epoch1,2)) with avg(5x5) : 29_v2_01(oof=0.5870, LB=), use Shujun's features, catboost, LB=0.571  \n",
    "* v22 : 99_v1_06_02(replaced by all_data 32_v2_01(deberta-large) + 32_vl_01(deberta-v3-large)) : 999_v1_22(single stacking, deberta-large, seed100) + 999_v1_23(single stacking, deberta-v3-large, seed100), avg(5x5xnum_models) LB=0.563  \n",
    "* v23 : 99_v1_06_06(replaced by all_data 32_v2_01(deberta-large) + 32_vl_01(deberta-v3-large) + 32_v2_02(deberta-xlarge)) : 999_v1_22(single stacking, deberta-large, seed100) + 999_v1_23(single stacking, deberta-v3-large, seed100) + 999_v1_25(single stacking, deberta-xlarge, seed100), avg(5x5xnum_models) LB=0.566  \n",
    "  \n",
    "  \n",
    "  --- rnn w/ 2nd round pl ---  \n",
    "* v25 : 999_v1_29 : 34_v2_02(CV=0.5865, LB=), use Shujun's features, catboost, CV=0.5836, avg(5x5xnum_models) LB=0.568  \n",
    "* v26 : 99_v1_06_17 : 999_v1_22(single stacking, deberta-large, seed100) + 999_v1_23(single stacking, deberta-v3-large, seed100) + 999_v1_29(single stacking, deberta-large, seed100, lstm, 2nd pl) + 999_v1_30(single stacking, deberta-v3-large, seed100, lstm, 2nd pl), oof=0.5753, avg(5x5xnum_models) LB=0.563  \n",
    "  \n",
    "  \n",
    "  --- sw(768,512,128) at inference + weight tuning ---  \n",
    "* v27 : 99_v1_07_01 : 999_v1_31(single stacking, deberta-large, seed100, sw(768,512,128)) + 999_v1_32(single stacking, deberta-v3-large, seed100, sw(768,512,128)), w=(0.43203959 0.56796041), oof=0.5748, avg(5x5xnum_models) LB=0.563  \n",
    "* v28 : 999_v1_34 : 34_vl_01(sw768-512-128, CV=0.5769, LB=), use Shujun's features, lgb, oof=0.5751, avg(5x5) LB=  \n",
    "  \n",
    "  \n",
    "  --- best weight tuning ---  \n",
    "* v29 : 34_v2_02(deberta-large, seed100, sw(768,512,128)) + 34_vl_01(deberta-v3-large, seed100, sw(768,512,128)) + 999_v1_22(single stacking, deberta-large, seed100) + 999_v1_23(single stacking, deberta-v3-large, seed100), w=(0.23678063 0.42236033 0.14750601 0.19335303), oof=0.5702, LB=  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05339700",
   "metadata": {
    "papermill": {
     "duration": 0.006191,
     "end_time": "2022-08-22T03:10:23.130494",
     "exception": false,
     "start_time": "2022-08-22T03:10:23.124303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9c7182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:23.153030Z",
     "iopub.status.busy": "2022-08-22T03:10:23.152522Z",
     "iopub.status.idle": "2022-08-22T03:10:23.205208Z",
     "shell.execute_reply": "2022-08-22T03:10:23.204315Z"
    },
    "papermill": {
     "duration": 0.065107,
     "end_time": "2022-08-22T03:10:23.207345",
     "exception": false,
     "start_time": "2022-08-22T03:10:23.142238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/nbroad/deberta-v2-3-fast-tokenizer\n",
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# This must be done before importing transformers\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59f720e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:23.221969Z",
     "iopub.status.busy": "2022-08-22T03:10:23.220504Z",
     "iopub.status.idle": "2022-08-22T03:10:29.726562Z",
     "shell.execute_reply": "2022-08-22T03:10:29.725522Z"
    },
    "papermill": {
     "duration": 6.515464,
     "end_time": "2022-08-22T03:10:29.729002",
     "exception": false,
     "start_time": "2022-08-22T03:10:23.213538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers 4.18.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__name__, transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a21b7d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:29.742494Z",
     "iopub.status.busy": "2022-08-22T03:10:29.742023Z",
     "iopub.status.idle": "2022-08-22T03:10:29.754786Z",
     "shell.execute_reply": "2022-08-22T03:10:29.753780Z"
    },
    "papermill": {
     "duration": 0.023004,
     "end_time": "2022-08-22T03:10:29.757834",
     "exception": false,
     "start_time": "2022-08-22T03:10:29.734830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models.py\n",
    "\n",
    "import torch\n",
    "\n",
    "def to_gpu(data):\n",
    "    '''\n",
    "    https://www.kaggle.com/code/tascj0/a-text-span-detector\n",
    "    '''\n",
    "    if isinstance(data, dict):\n",
    "        return {k: to_gpu(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [to_gpu(v) for v in data]\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.cuda()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "def to_np(t):\n",
    "    '''\n",
    "    https://www.kaggle.com/code/tascj0/a-text-span-detector\n",
    "    '''\n",
    "    if isinstance(t, torch.Tensor):\n",
    "        return t.data.cpu().numpy()\n",
    "    else:\n",
    "        return t\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import (AutoConfig, AutoModel, AutoTokenizer, AutoModelForTokenClassification)\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class ResidualLSTM(nn.Module):\n",
    "    '''Based on Shujun's code'''\n",
    "    def __init__(self, d_model, rnn='GRU'):\n",
    "        super(ResidualLSTM, self).__init__()\n",
    "        self.downsample=nn.Linear(d_model,d_model//2)\n",
    "        if rnn=='GRU':\n",
    "            self.LSTM=nn.GRU(d_model//2, d_model//2, num_layers=2, bidirectional=False, dropout=0.2)\n",
    "        else:\n",
    "            self.LSTM=nn.LSTM(d_model//2, d_model//2, num_layers=2, bidirectional=False, dropout=0.2)\n",
    "        self.linear=nn.Linear(d_model//2, d_model)\n",
    "        self.norm= nn.LayerNorm(d_model)\n",
    "    def forward(self, x):\n",
    "        res=x\n",
    "        x=self.downsample(x)\n",
    "        x, _ = self.LSTM(x)\n",
    "        x = self.linear(x)\n",
    "        x=res+x\n",
    "        return self.norm(x)\n",
    "    \n",
    "class LSTMBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_layers=1, p_drop=0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=in_channels,\n",
    "                             hidden_size=out_channels,\n",
    "                             num_layers=num_layers,\n",
    "                             dropout=p_drop,\n",
    "                             batch_first=True, \n",
    "                             bidirectional=True)\n",
    "    def forward(self, x): #(bs,num_tokens,hidden_size)\n",
    "        x,_ = self.lstm(x)\n",
    "        return x\n",
    "    \n",
    "class GRUBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_layers=1, p_drop=0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.GRU(input_size=in_channels,\n",
    "                           hidden_size=out_channels,\n",
    "                           num_layers=num_layers,\n",
    "                           dropout=p_drop,\n",
    "                           batch_first=True, \n",
    "                           bidirectional=True)\n",
    "    def forward(self, x): #(bs,num_tokens,hidden_size)\n",
    "        x,_ = self.lstm(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_layers=1, nhead=8):\n",
    "        super().__init__()\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(d_model=in_channels,nhead=nhead),\n",
    "                                                 num_layers=num_layers)\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 model_name, \n",
    "                 tokenizer,\n",
    "                 num_labels, \n",
    "                 num_labels_2,\n",
    "                 rnn='none',\n",
    "                 loss='mse',\n",
    "                 head='simple',\n",
    "                 multi_layers=1,\n",
    "                 p_drop=0,\n",
    "                 l2norm='false',\n",
    "                 s=30,\n",
    "                 freeze_layers='false',\n",
    "                 mt='false',\n",
    "                 window_size=-100,\n",
    "                 inner_len=-100,\n",
    "                 edge_len=-100,\n",
    "                 model_pretraining=None,\n",
    "                 **kwargs,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.num_labels_2 = num_labels_2\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_name = model_name\n",
    "        self.loss = loss\n",
    "        self.multi_layers = multi_layers\n",
    "        self.l2norm = l2norm\n",
    "        self.s = s\n",
    "        self.mt = mt\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.inner_len = inner_len\n",
    "        self.edge_len = edge_len\n",
    "        \n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"add_pooling_layer\": False,\n",
    "                \"num_labels\": self.num_labels,\n",
    "            }\n",
    "        )\n",
    "        if model_pretraining is not None and 'longformer' in model_name:\n",
    "            self.transformer = model_pretraining.model.longformer\n",
    "        else:\n",
    "            self.transformer = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "            \n",
    "        # resize\n",
    "        self.transformer.resize_token_embeddings(len(tokenizer))\n",
    "            \n",
    "        if rnn=='none':\n",
    "            self.rnn = nn.Identity()\n",
    "        elif rnn=='lstm':\n",
    "            self.rnn = ResidualLSTM(self.config.hidden_size*self.multi_layers, rnn='LSTM')\n",
    "        elif rnn=='gru':\n",
    "            self.rnn = ResidualLSTM(self.config.hidden_size*self.multi_layers, rnn='GRU')\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "        if head=='simple':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Dropout(p_drop),\n",
    "                nn.Linear(self.config.hidden_size*self.multi_layers, self.num_labels)\n",
    "            )\n",
    "        elif head=='norm':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.LayerNorm(self.config.hidden_size*self.multi_layers),\n",
    "                nn.Linear(self.config.hidden_size*self.multi_layers, 512),\n",
    "                nn.GELU(),\n",
    "                nn.LayerNorm(512),\n",
    "                nn.Linear(512, self.num_labels),\n",
    "            )\n",
    "        else:\n",
    "            raise Exception()\n",
    "        \n",
    "        # for multi-task\n",
    "        if self.mt=='true':\n",
    "            self.head2 = nn.Sequential(\n",
    "                nn.Dropout(p_drop),\n",
    "                nn.Linear(self.config.hidden_size*self.multi_layers, self.num_labels_2)\n",
    "            )\n",
    "        \n",
    "        if loss=='xentropy':\n",
    "            self.loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "        else:\n",
    "            raise Exception()\n",
    "            \n",
    "    def forward_logits(self, input_ids, attention_mask, span_list, save_prob_seq=False):\n",
    "        assert self.multi_layers==1\n",
    "        \n",
    "        # sliding window approach to deal with longer tokens than max_length\n",
    "        # https://www.kaggle.com/competitions/feedback-prize-2021/discussion/313235\n",
    "        L = input_ids.size(1)\n",
    "        if self.window_size==-100 or L<=self.window_size:\n",
    "            x = self.transformer(input_ids=input_ids,\n",
    "                                 attention_mask=attention_mask).last_hidden_state\n",
    "        else:\n",
    "            assert len(input_ids)==1\n",
    "            segments = (L - self.window_size) // self.inner_len\n",
    "            if (L - self.window_size) % self.inner_len > self.edge_len:\n",
    "                segments += 1\n",
    "            elif segments == 0:\n",
    "                segments += 1\n",
    "            x = self.transformer(input_ids=input_ids[:,:self.window_size],\n",
    "                                 attention_mask=attention_mask[:,:self.window_size]).last_hidden_state\n",
    "            for i in range(1,segments+1):\n",
    "                start = self.window_size - self.edge_len + (i-1)*self.inner_len\n",
    "                end   = self.window_size - self.edge_len + (i-1)*self.inner_len + self.window_size\n",
    "                end = min(end, L)\n",
    "                x_next = self.transformer(input_ids=input_ids[:,start:end],\n",
    "                                          attention_mask=attention_mask[:,start:end]).last_hidden_state\n",
    "                if i==segments:\n",
    "                    x_next = x_next[:,self.edge_len:]\n",
    "                else:\n",
    "                    x_next = x_next[:,self.edge_len:self.edge_len+self.inner_len]\n",
    "                x = torch.cat([x,x_next], dim=1)\n",
    "            \n",
    "        #hidden_states = self.rnn(x) # (bs=1,num_tokens,hidden_size*multi_layers)\n",
    "        hidden_states = x\n",
    "        hidden_states = hidden_states.squeeze(0) # (num_tokens,hidden_size*multi_layers)\n",
    "            \n",
    "        span_list = span_list[0]\n",
    "        span_list_next = span_list[1:]+[-1]\n",
    "\n",
    "        logits_list = []\n",
    "        for i_token, i_token_next in zip(span_list, span_list_next):\n",
    "            tmp_logits = hidden_states[i_token:i_token_next,:].mean(dim=0) # (hidden_size*multi_layers)\n",
    "            logits_list.append(tmp_logits)\n",
    "        logits = torch.stack(logits_list) # (bs=num_discourse,hidden_size*multi_layers)\n",
    "        \n",
    "        # apply rnn\n",
    "        logits = logits.unsqueeze(0) # (bs=1,num_discourse,hidden_size*multi_layers)\n",
    "        logits = self.rnn(logits)\n",
    "        logits = logits.squeeze(0) # (bs=num_discourse,hidden_size*multi_layers)\n",
    "        \n",
    "        logits = self.head(logits) # (bs=num_discourse,num_labels)\n",
    "        \n",
    "        if save_prob_seq:\n",
    "            prob_seq = []\n",
    "            for i_token, i_token_next in zip(span_list, span_list_next):\n",
    "                tmp_logits = hidden_states[i_token:i_token_next,:] # (num_tokens,hidden_size*multi_layers)\n",
    "                tmp_prob_seq = self.head(tmp_logits).softmax(-1).detach().cpu().numpy() #(num_tokens,num_labels)\n",
    "                prob_seq.append(tmp_prob_seq)\n",
    "            return logits, prob_seq\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def test_step(self, batch):\n",
    "        data = to_gpu(batch)\n",
    "        input_data = {\n",
    "            'input_ids':data['input_ids'],\n",
    "            'attention_mask':data['attention_mask'],\n",
    "            'span_list':data['span_list'],\n",
    "            'save_prob_seq':True,\n",
    "        }\n",
    "        logits, prob_seq = self.forward_logits(**input_data)\n",
    "        if self.loss in ['xentropy']:\n",
    "            pred = logits.softmax(-1).detach().cpu().numpy().reshape(-1,self.num_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        return {\n",
    "            'pred':pred,\n",
    "            'discourse_ids':data['discourse_ids'],\n",
    "            'prob_seq':prob_seq,\n",
    "        }\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "\n",
    "# be careful for the order below\n",
    "discourse_type_list = [\n",
    "    'Lead',\n",
    "    'Position',\n",
    "    'Claim',\n",
    "    'Counterclaim',\n",
    "    'Rebuttal',\n",
    "    'Evidence',\n",
    "    'Concluding Statement'\n",
    "]\n",
    "    \n",
    "class DatasetTest(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.unique_ids = sorted(df['essay_id'].unique())\n",
    "        self.tokenizer = tokenizer\n",
    "        self.discourse_type_token_ids_dict = {\n",
    "            discourse_type : tokenizer.convert_tokens_to_ids(f'[{discourse_type.upper()}]')\n",
    "            for discourse_type in discourse_type_list\n",
    "        }\n",
    "        self.inv_discourse_type_token_ids_dict = {v:k for k,v in self.discourse_type_token_ids_dict.items()}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.unique_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        essay_id = self.unique_ids[idx]\n",
    "        sample_df = self.df[self.df['essay_id']==essay_id].reset_index(drop=True)\n",
    "        discourse_ids = sample_df['discourse_id'].values\n",
    "\n",
    "        text = ''\n",
    "        discourse_types = []\n",
    "        for discourse_type, discourse_text in zip(\n",
    "            sample_df['discourse_type'].values, sample_df['discourse_text'].values\n",
    "        ):\n",
    "            text += f' [{discourse_type.upper()}] {discourse_text}'\n",
    "            discourse_types.append(discourse_type.upper())\n",
    "        \n",
    "        tokens = self.tokenizer.encode_plus(text, add_special_tokens=True)\n",
    "        input_ids = torch.LongTensor(tokens['input_ids'])\n",
    "        attention_mask = torch.ones(len(input_ids)).long()\n",
    "        \n",
    "        span_list = []\n",
    "        for i_token, input_id in enumerate(tokens['input_ids']):\n",
    "            if input_id in self.discourse_type_token_ids_dict.values():\n",
    "                span_list.append(i_token)\n",
    "        \n",
    "        return dict(\n",
    "            essay_id = essay_id,\n",
    "            discourse_ids = discourse_ids,\n",
    "            text = text,\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            discourse_types = discourse_types,\n",
    "            span_list = span_list,\n",
    "        )\n",
    "        \n",
    "class CustomCollator(object):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __call__(self, samples):\n",
    "        output = dict()\n",
    "        \n",
    "        for k in samples[0].keys():\n",
    "            output[k] = [sample[k] for sample in samples]\n",
    "        \n",
    "        # calculate max token length of this batch\n",
    "        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n",
    "        \n",
    "        # add padding\n",
    "        if self.tokenizer.padding_side == \"right\":\n",
    "            output[\"input_ids\"] = [s.tolist() + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n",
    "            output[\"attention_mask\"] = [s.tolist() + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n",
    "        else:\n",
    "            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s.tolist() for s in output[\"input_ids\"]]\n",
    "            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s.tolist() for s in output[\"attention_mask\"]]\n",
    "            \n",
    "        output[\"input_ids\"] = torch.LongTensor(output[\"input_ids\"])\n",
    "        output[\"attention_mask\"] = torch.LongTensor(output[\"attention_mask\"])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bff3c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:29.770777Z",
     "iopub.status.busy": "2022-08-22T03:10:29.770512Z",
     "iopub.status.idle": "2022-08-22T03:10:29.776090Z",
     "shell.execute_reply": "2022-08-22T03:10:29.775205Z"
    },
    "papermill": {
     "duration": 0.014186,
     "end_time": "2022-08-22T03:10:29.778094",
     "exception": false,
     "start_time": "2022-08-22T03:10:29.763908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing models_detector.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models_detector.py\n",
    "\n",
    "from torch import nn\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "class TextSpanDetectorOriginal(nn.Module):\n",
    "    def __init__(self, arch, num_classes=7, local_files_only=True):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(\n",
    "            arch,\n",
    "            num_labels=1 + 2 + num_classes,\n",
    "            local_files_only=local_files_only\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            arch, \n",
    "            local_files_only=local_files_only\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2ddd16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:29.791560Z",
     "iopub.status.busy": "2022-08-22T03:10:29.790935Z",
     "iopub.status.idle": "2022-08-22T03:10:29.800397Z",
     "shell.execute_reply": "2022-08-22T03:10:29.799359Z"
    },
    "papermill": {
     "duration": 0.018699,
     "end_time": "2022-08-22T03:10:29.802500",
     "exception": false,
     "start_time": "2022-08-22T03:10:29.783801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import torch\n",
    "print(torch.__name__, torch.__version__)\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from os.path import join as opj\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--fold\", type=int, default=-1, required=False)\n",
    "    parser.add_argument(\"--seed\", type=int, default=-1, required=False)\n",
    "    parser.add_argument(\"--model\", type=str, required=True)\n",
    "    parser.add_argument(\"--model_name\", type=str, required=True)\n",
    "    parser.add_argument(\"--input_path\", type=str, default='../input/feedback-prize-effectiveness/', required=False)\n",
    "    \n",
    "    parser.add_argument(\"--test_batch_size\", type=int, default=1, required=False)\n",
    "    parser.add_argument(\"--pretrain_path\", type=str, default='none', required=False)\n",
    "    parser.add_argument(\"--rnn\", type=str, default='none', required=False)\n",
    "    parser.add_argument(\"--head\", type=str, default='simple', required=False)\n",
    "    parser.add_argument(\"--loss\", type=str, default='xentropy', required=False)\n",
    "    parser.add_argument(\"--multi_layers\", type=int, default=1, required=False)\n",
    "    parser.add_argument(\"--num_labels\", type=int, default=3, required=False)\n",
    "    parser.add_argument(\"--num_labels_2\", type=int, default=7, required=False)\n",
    "    parser.add_argument(\"--l2norm\", type=str, default='false', required=False)\n",
    "    parser.add_argument(\"--max_length\", type=int, default=1024, required=False)\n",
    "    parser.add_argument(\"--mt\", type=str, default='false', required=False)\n",
    "    \n",
    "    parser.add_argument(\"--window_size\", type=int, default=-100, required=False)\n",
    "    parser.add_argument(\"--inner_len\", type=int, default=-100, required=False)\n",
    "    parser.add_argument(\"--edge_len\", type=int, default=-100, required=False)\n",
    "    \n",
    "    return parser.parse_args()\n",
    "\n",
    "    \n",
    "from models import Model, DatasetTest, CustomCollator\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    NUM_JOBS = 2\n",
    "    args = parse_args()\n",
    "        \n",
    "    #train_df = pd.read_csv(opj(args.input_path, 'train.csv'))\n",
    "    test_df = pd.read_csv(opj(args.input_path, 'test.csv'))\n",
    "    #test_df = pd.read_csv(opj(args.input_path, 'train.csv'))\n",
    "    sub_df = pd.read_csv(opj(args.input_path, 'sample_submission.csv'))\n",
    "    \n",
    "    #unique_ids = test_df['essay_id'].unique()[:100]\n",
    "    #test_df = test_df[test_df['essay_id'].isin(unique_ids)].reset_index(drop=True)\n",
    "\n",
    "    #print('train_df.shape = ', train_df.shape)\n",
    "    print('test_df.shape = ', test_df.shape)\n",
    "    print('sub_df.shape = ', sub_df.shape)\n",
    "\n",
    "    LABEL = 'discourse_effectiveness'\n",
    "    \n",
    "    os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "    \n",
    "    from models import discourse_type_list\n",
    "    if ('deberta-v2' in args.model) or ('deberta-v3' in args.model):\n",
    "        print('use DebertaV2TokenizerFast')\n",
    "        from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n",
    "        tokenizer = DebertaV2TokenizerFast.from_pretrained(args.model, trim_offsets=False)\n",
    "        special_tokens_dict = {'additional_special_tokens': ['\\n\\n'] + [f'[{s.upper()}]' for s in discourse_type_list]}\n",
    "        _ = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    else:\n",
    "        from transformers import AutoTokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.model, trim_offsets=False)\n",
    "        special_tokens_dict = {'additional_special_tokens': [f'[{s.upper()}]' for s in discourse_type_list]}\n",
    "        _ = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "        \n",
    "    #print('tokenizer = ', tokenizer)\n",
    "        \n",
    "    test_dataset = DatasetTest(\n",
    "        test_df,\n",
    "        tokenizer,\n",
    "    )\n",
    "    from torch.utils.data import DataLoader\n",
    "    test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=args.test_batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=CustomCollator(tokenizer),\n",
    "            num_workers=NUM_JOBS,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "    \n",
    "    #model\n",
    "    model_pretraining = None\n",
    "    if 'longformer' in args.model:\n",
    "        from models_detector import TextSpanDetectorOriginal\n",
    "        model_pretraining = TextSpanDetectorOriginal(args.model)\n",
    "    model = Model(args.model, \n",
    "                  tokenizer,\n",
    "                  num_labels=args.num_labels, \n",
    "                  num_labels_2=args.num_labels_2,\n",
    "                  rnn=args.rnn,\n",
    "                  loss=args.loss,\n",
    "                  head=args.head,\n",
    "                  multi_layers=args.multi_layers,\n",
    "                  l2norm=args.l2norm,\n",
    "                  max_length=args.max_length,\n",
    "                  mt=args.mt,\n",
    "                  window_size=args.window_size,\n",
    "                  inner_len=args.inner_len,\n",
    "                  edge_len=args.edge_len,\n",
    "                  model_pretraining=model_pretraining,\n",
    "                 )\n",
    "    if args.fold!=-1:\n",
    "        weight_path = opj(args.model, f'model_fold{args.fold}.pth')\n",
    "    elif args.seed!=-1:\n",
    "        weight_path = opj(args.model, f'model_seed{args.seed}.pth')\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    outputs = []\n",
    "    for batch_idx, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        with torch.no_grad():\n",
    "            output = model.test_step(batch)\n",
    "            outputs.append(output)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "            \n",
    "    preds = []\n",
    "    discourse_ids = []\n",
    "    prob_seqs = []\n",
    "    for o in outputs:\n",
    "        preds.append(o['pred'])\n",
    "        discourse_ids.extend(o['discourse_ids'])\n",
    "        prob_seqs.extend(o['prob_seq'])\n",
    "    preds = np.vstack(preds)\n",
    "    discourse_ids = np.hstack(discourse_ids)\n",
    "    \n",
    "    print('discourse_ids.shape = ', discourse_ids.shape)\n",
    "    print('preds.shape = ', preds.shape)\n",
    "    print('len(prob_seqs) = ', len(prob_seqs))\n",
    "    \n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['discourse_id'] = discourse_ids\n",
    "    pred_df['Ineffective'] = preds[:,0]\n",
    "    pred_df['Adequate'] = preds[:,1]\n",
    "    pred_df['Effective'] = preds[:,2]\n",
    "    pred_df['prob_seq'] = prob_seqs\n",
    "    \n",
    "    pred_df = test_df[['discourse_id']].merge(pred_df, on='discourse_id', how='left')\n",
    "    \n",
    "    pred_name = args.model.split('/')[-1]\n",
    "    if 'fold' in pred_name:\n",
    "        pred_name = pred_name.replace('-fold012','').replace('-fold34','')\n",
    "        \n",
    "    if args.fold!=-1:\n",
    "        print(f'saving raw_pred_{pred_name}_fold{args.fold}.csv...')\n",
    "        pred_df.to_csv(f'raw_pred_{pred_name}_fold{args.fold}.csv', index=False)\n",
    "        print(f'saving raw_pred_{pred_name}_fold{args.fold}.csv, done')\n",
    "    elif args.seed!=-1:\n",
    "        print(f'saving raw_pred_{pred_name}_seed{args.seed}.csv...')\n",
    "        pred_df.to_csv(f'raw_pred_{pred_name}_seed{args.seed}.csv', index=False)\n",
    "        print(f'saving raw_pred_{pred_name}_seed{args.seed}.csv, done')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a3ba1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:29.817070Z",
     "iopub.status.busy": "2022-08-22T03:10:29.816771Z",
     "iopub.status.idle": "2022-08-22T03:10:29.824503Z",
     "shell.execute_reply": "2022-08-22T03:10:29.823407Z"
    },
    "papermill": {
     "duration": 0.017503,
     "end_time": "2022-08-22T03:10:29.826492",
     "exception": false,
     "start_time": "2022-08-22T03:10:29.808989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing shujun_features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile shujun_features.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_xgb_features(train_df, prob_sequences, use_prob_seq=True):\n",
    "    '''\n",
    "    prob_seq is the sequence of token probs from each discourse\n",
    "    '''\n",
    "    \n",
    "    if use_prob_seq:\n",
    "        # 10 features : instability_0,...,instability_3, begin_0,...,begin_2, end_0,...,end_2\n",
    "        features2calculate=[f\"instability_{i}\" for i in range(4)]+\\\n",
    "        [f\"begin_{i}\" for i in range(3)]+\\\n",
    "        [f\"end_{i}\" for i in range(3)]\n",
    "        calculated_features=[]\n",
    "        for i,prob_seq in tqdm(enumerate(prob_sequences)):\n",
    "            tmp=[]\n",
    "            prob_seq=np.array(prob_seq)\n",
    "            tmp.append(np.diff(prob_seq[:,:],0).mean(0)) # 3\n",
    "            tmp.append([(np.diff(prob_seq[:,[1,2]].sum(1))**2).mean()]) # 1\n",
    "            tmp.append(prob_seq[:5,:].mean(0)) # 3\n",
    "            tmp.append(prob_seq[-5:,:].mean(0)) # 3\n",
    "            calculated_features.append(np.concatenate(tmp))\n",
    "        calculated_features=np.array(calculated_features)\n",
    "        print('calculated_features.shape = ', calculated_features.shape)\n",
    "        train_df[features2calculate]=calculated_features # 10 features\n",
    "        train_df['len']=[len(s) for s in prob_sequences]\n",
    "\n",
    "    p_features=[]\n",
    "    n_features=[]\n",
    "    neighbor_features=['Ineffective','Adequate','Effective','discourse_type']\n",
    "    neighbor_features_values=train_df[neighbor_features].values\n",
    "    for i in tqdm(range(len(train_df))):\n",
    "        if i>1 and train_df['essay_id'].iloc[i]==train_df['essay_id'].iloc[i-1]:\n",
    "            p_features.append(neighbor_features_values[i-1])\n",
    "        else:\n",
    "            p_features.append(neighbor_features_values[i])\n",
    "\n",
    "        if i<(len(train_df)-1) and train_df['essay_id'].iloc[i]==train_df['essay_id'].iloc[i+1]:\n",
    "            n_features.append(neighbor_features_values[i+1])\n",
    "        else:\n",
    "            n_features.append(neighbor_features_values[i])\n",
    "\n",
    "    train_df[[f+\"_previous\" for f in neighbor_features]]=p_features\n",
    "    train_df[[f+\"_next\" for f in neighbor_features]]=n_features\n",
    "\n",
    "    train_df['mean_Ineffective']=train_df.groupby(\"essay_id\")[\"Ineffective\"].transform(\"mean\")\n",
    "    train_df['mean_Adequate']=train_df.groupby(\"essay_id\")[\"Adequate\"].transform(\"mean\")\n",
    "    train_df['mean_Effective']=train_df.groupby(\"essay_id\")[\"Effective\"].transform(\"mean\")\n",
    "\n",
    "    train_df['std_Ineffective']=train_df.groupby(\"essay_id\")[\"Ineffective\"].transform(\"std\")\n",
    "    train_df['std_Adequate']=train_df.groupby(\"essay_id\")[\"Adequate\"].transform(\"std\")\n",
    "    train_df['std_Effective']=train_df.groupby(\"essay_id\")[\"Effective\"].transform(\"std\")\n",
    "\n",
    "    train_df['discourse_count']=train_df.groupby(\"essay_id\")['discourse_type'].transform(\"count\")\n",
    "\n",
    "    cnts=train_df.groupby('essay_id')['discourse_type'].apply(lambda x: x.value_counts())\n",
    "\n",
    "    discourse_types=['Claim','Evidence','Concluding Statement','Lead','Position','Counterclaim','Rebuttal']\n",
    "    value_count_hash={}\n",
    "    for t in discourse_types:\n",
    "        value_count_hash[t]={}\n",
    "    for key in cnts.keys():\n",
    "        value_count_hash[key[1]][key[0]]=cnts[key]\n",
    "\n",
    "    discourse_cnts=[]    \n",
    "    for essay_id in train_df['essay_id'].unique():\n",
    "        row=[essay_id]\n",
    "        for d in discourse_types:\n",
    "            try:\n",
    "                row.append(value_count_hash[d][essay_id])\n",
    "            except:\n",
    "                row.append(0)\n",
    "        discourse_cnts.append(row)\n",
    "\n",
    "    discourse_cnts=pd.DataFrame(discourse_cnts,columns=['essay_id']+[f'{d}_count' for d in discourse_types])    \n",
    "\n",
    "    train_df=train_df.merge(discourse_cnts,how='left',on='essay_id')\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0183f5d",
   "metadata": {
    "papermill": {
     "duration": 0.006028,
     "end_time": "2022-08-22T03:10:29.838512",
     "exception": false,
     "start_time": "2022-08-22T03:10:29.832484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cc4ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:29.852686Z",
     "iopub.status.busy": "2022-08-22T03:10:29.852436Z",
     "iopub.status.idle": "2022-08-22T03:10:29.855947Z",
     "shell.execute_reply": "2022-08-22T03:10:29.854976Z"
    },
    "papermill": {
     "duration": 0.012834,
     "end_time": "2022-08-22T03:10:29.857839",
     "exception": false,
     "start_time": "2022-08-22T03:10:29.845005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = 'false'\n",
    "#DEBUG = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a858684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:29.870749Z",
     "iopub.status.busy": "2022-08-22T03:10:29.870474Z",
     "iopub.status.idle": "2022-08-22T03:10:30.131445Z",
     "shell.execute_reply": "2022-08-22T03:10:30.130464Z"
    },
    "papermill": {
     "duration": 0.269998,
     "end_time": "2022-08-22T03:10:30.133740",
     "exception": false,
     "start_time": "2022-08-22T03:10:29.863742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('../input/feedback-prize-effectiveness/train.csv')\n",
    "test_df = pd.read_csv('../input/feedback-prize-effectiveness/test.csv')\n",
    "#test_df = train_df.copy()\n",
    "\n",
    "IS_PRIVATE = True\n",
    "# if DEBUG=='false':\n",
    "#     if len(test_df)==10:\n",
    "#         IS_PRIVATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3b01f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:30.147879Z",
     "iopub.status.busy": "2022-08-22T03:10:30.147020Z",
     "iopub.status.idle": "2022-08-22T03:10:30.155081Z",
     "shell.execute_reply": "2022-08-22T03:10:30.154195Z"
    },
    "papermill": {
     "duration": 0.016855,
     "end_time": "2022-08-22T03:10:30.156982",
     "exception": false,
     "start_time": "2022-08-22T03:10:30.140127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    # (model_name, num_fold, weight, stacking_path, num_stacking_fold)\n",
    "    ('fb2-34-v2-02-deberta-large',5,0.23678063, 'none','none'), # 2nd round pseudo-label, 5fold, residual lstm\n",
    "    ('fb2-34-vl-01-deberta-v3-large',5,0.42236033, 'none','none'), # 2nd round pseudo-label, 5fold, residual lstm\n",
    "    ('fb2-29-v2-01-deberta-large',5,0.14750601, f'../input/fb2-999-v1-22',5), # 1st round pseudo-label, 5fold, catboost\n",
    "    ('fb2-29-vl-01-deberta-v3-large',5,0.19335303, f'../input/fb2-999-v1-23',5), # 1st round pseudo-label, 5fold, catboost\n",
    "]\n",
    "model_name_list = [name for (name,_,_,_,_) in model_list]\n",
    "num_fold_list = [num_fold for (_,num_fold,_,_,_) in model_list]\n",
    "w_list = [w for (_,_,w,_,_) in model_list]\n",
    "stacking_path_list = [stacking_path for (_,_,_,stacking_path,_) in model_list]\n",
    "num_stacking_fold_list = [num_stacking_fold for (_,_,_,_,num_stacking_fold) in model_list]\n",
    "\n",
    "# for debug\n",
    "if DEBUG=='true': \n",
    "    model_list = [(name,1,w,stacking_path,num_stacking_fold) for (name,nu_mfolds,w,stacking_path,num_stacking_fold) in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee75a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:10:30.169709Z",
     "iopub.status.busy": "2022-08-22T03:10:30.169453Z",
     "iopub.status.idle": "2022-08-22T03:13:31.413023Z",
     "shell.execute_reply": "2022-08-22T03:13:31.411801Z"
    },
    "papermill": {
     "duration": 181.252792,
     "end_time": "2022-08-22T03:13:31.415556",
     "exception": false,
     "start_time": "2022-08-22T03:10:30.162764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.51s/it]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold0.csv...\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold0.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold1.csv...\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold1.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold2.csv...\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold2.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold3.csv...\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold3.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold4.csv...\r\n",
      "saving raw_pred_fb2-34-vl-01-deberta-v3-large_fold4.csv, done\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "if IS_PRIVATE:\n",
    "    MODEL_NAME = 'microsoft/deberta-v3-large' #seed100 5fold xentropy, residual lstm\n",
    "    MODEL = '../input/fb2-34-vl-01-deberta-v3-large'\n",
    "    NUM_LABELS = 3\n",
    "    WINDOW = 768 #512\n",
    "    INNER = 512 #384\n",
    "    EDGE = 128 #64\n",
    "    RNN = 'lstm'\n",
    "    if MODEL.split('/')[-1] in model_name_list:\n",
    "        !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 0 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "        if DEBUG=='false':\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 1 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 2 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 3 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 4 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08130d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:13:31.433046Z",
     "iopub.status.busy": "2022-08-22T03:13:31.432731Z",
     "iopub.status.idle": "2022-08-22T03:17:07.345713Z",
     "shell.execute_reply": "2022-08-22T03:17:07.344210Z"
    },
    "papermill": {
     "duration": 215.924924,
     "end_time": "2022-08-22T03:17:07.348633",
     "exception": false,
     "start_time": "2022-08-22T03:13:31.423709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold0.csv...\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold0.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold1.csv...\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold1.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold2.csv...\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold2.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold3.csv...\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold3.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold4.csv...\r\n",
      "saving raw_pred_fb2-34-v2-02-deberta-large_fold4.csv, done\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "if IS_PRIVATE:\n",
    "    MODEL_NAME = 'microsoft/deberta-large' #seed100 5fold xentropy, residual lstm\n",
    "    MODEL = '../input/fb2-34-v2-02-deberta-large'\n",
    "    NUM_LABELS = 3\n",
    "    WINDOW = 768 #512\n",
    "    INNER = 512 #384\n",
    "    EDGE = 128 #64\n",
    "    RNN = 'lstm'\n",
    "    if MODEL.split('/')[-1] in model_name_list:\n",
    "        !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 0 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "        if DEBUG=='false':\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 1 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 2 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 3 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 4 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE --rnn $RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd87f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:17:07.370000Z",
     "iopub.status.busy": "2022-08-22T03:17:07.369674Z",
     "iopub.status.idle": "2022-08-22T03:21:15.430531Z",
     "shell.execute_reply": "2022-08-22T03:21:15.428986Z"
    },
    "papermill": {
     "duration": 248.074708,
     "end_time": "2022-08-22T03:21:15.433942",
     "exception": false,
     "start_time": "2022-08-22T03:17:07.359234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold0.csv...\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold0.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.62it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold1.csv...\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold1.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold2.csv...\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold2.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold3.csv...\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold3.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "use DebertaV2TokenizerFast\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold4.csv...\r\n",
      "saving raw_pred_fb2-29-vl-01-deberta-v3-large_fold4.csv, done\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "if IS_PRIVATE:\n",
    "    MODEL_NAME = 'microsoft/deberta-v3-large' #seed100 5fold xentropy\n",
    "    MODEL = '../input/fb2-29-vl-01-deberta-v3-large'\n",
    "    NUM_LABELS = 3\n",
    "    WINDOW = 512\n",
    "    INNER = 384\n",
    "    EDGE = 64\n",
    "    if MODEL.split('/')[-1] in model_name_list:\n",
    "        !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 0 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "        if DEBUG=='false':\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 1 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 2 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 3 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 4 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16fcabc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:21:15.461887Z",
     "iopub.status.busy": "2022-08-22T03:21:15.461560Z",
     "iopub.status.idle": "2022-08-22T03:25:04.619858Z",
     "shell.execute_reply": "2022-08-22T03:25:04.618668Z"
    },
    "papermill": {
     "duration": 229.174598,
     "end_time": "2022-08-22T03:25:04.622380",
     "exception": false,
     "start_time": "2022-08-22T03:21:15.447782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold0.csv...\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold0.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold1.csv...\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold1.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.65it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold2.csv...\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold2.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.64it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold3.csv...\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold3.csv, done\r\n",
      "\r\n",
      "\r\n",
      "torch 1.11.0\r\n",
      "test_df.shape =  (10, 4)\r\n",
      "sub_df.shape =  (10, 4)\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\r\n",
      "discourse_ids.shape =  (10,)\r\n",
      "preds.shape =  (10, 3)\r\n",
      "len(prob_seqs) =  10\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold4.csv...\r\n",
      "saving raw_pred_fb2-29-v2-01-deberta-large_fold4.csv, done\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "if IS_PRIVATE:\n",
    "    MODEL_NAME = 'microsoft/deberta-large' #seed100 5fold xentropy\n",
    "    MODEL = '../input/fb2-29-v2-01-deberta-large'\n",
    "    NUM_LABELS = 3\n",
    "    WINDOW = 512\n",
    "    INNER = 384\n",
    "    EDGE = 64\n",
    "    if MODEL.split('/')[-1] in model_name_list:\n",
    "        !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 0 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "        if DEBUG=='false':\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 1 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 2 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 3 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE\n",
    "            !python inference.py --model_name $MODEL_NAME --model $MODEL --fold 4 --window_size $WINDOW --inner_len $INNER --edge_len $EDGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda279d2",
   "metadata": {
    "papermill": {
     "duration": 0.01238,
     "end_time": "2022-08-22T03:25:04.647910",
     "exception": false,
     "start_time": "2022-08-22T03:25:04.635530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6333099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:25:04.676025Z",
     "iopub.status.busy": "2022-08-22T03:25:04.675112Z",
     "iopub.status.idle": "2022-08-22T03:25:04.685131Z",
     "shell.execute_reply": "2022-08-22T03:25:04.684200Z"
    },
    "papermill": {
     "duration": 0.02627,
     "end_time": "2022-08-22T03:25:04.687024",
     "exception": false,
     "start_time": "2022-08-22T03:25:04.660754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fb2-34-v2-02-deberta-large', 5, 0.23678063, 'none', 'none'),\n",
       " ('fb2-34-vl-01-deberta-v3-large', 5, 0.42236033, 'none', 'none'),\n",
       " ('fb2-29-v2-01-deberta-large', 5, 0.14750601, '../input/fb2-999-v1-22', 5),\n",
       " ('fb2-29-vl-01-deberta-v3-large', 5, 0.19335303, '../input/fb2-999-v1-23', 5)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c817d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:25:04.714279Z",
     "iopub.status.busy": "2022-08-22T03:25:04.713552Z",
     "iopub.status.idle": "2022-08-22T03:25:05.412777Z",
     "shell.execute_reply": "2022-08-22T03:25:05.411817Z"
    },
    "papermill": {
     "duration": 0.715435,
     "end_time": "2022-08-22T03:25:05.415192",
     "exception": false,
     "start_time": "2022-08-22T03:25:04.699757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os.path import join as opj\n",
    "import joblib\n",
    "import catboost\n",
    "from shujun_features import get_xgb_features\n",
    "\n",
    "def stacking(_test_df, prob_sequences, stacking_path, num_stacking_fold, i_model, fold, num_fold, weight, use_prob_seq=False):\n",
    "    test_df = _test_df.copy()\n",
    "    \n",
    "    # generate features\n",
    "    test_df = get_xgb_features(test_df, prob_sequences, use_prob_seq=use_prob_seq)\n",
    "    print('test_df.shape = ', test_df.shape)\n",
    "    seq_cols = [f\"instability_{i}\" for i in range(4)] + [f\"begin_{i}\" for i in range(3)] + [f\"end_{i}\" for i in range(3)] + ['len']\n",
    "    \n",
    "    cols = ['discourse_type','discourse_type_previous','discourse_type_next']\n",
    "    cols += ['Ineffective','Adequate','Effective']\n",
    "    cols += [\n",
    "        'Ineffective_previous', 'Adequate_previous', 'Effective_previous', \n",
    "        'Ineffective_next', 'Adequate_next', 'Effective_next',\n",
    "        'mean_Ineffective', 'mean_Adequate', 'mean_Effective',\n",
    "        'std_Ineffective', 'std_Adequate', 'std_Effective', \n",
    "        'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count',\n",
    "        'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count'\n",
    "    ]\n",
    "    cols += seq_cols\n",
    "    print('cols = ', cols)\n",
    "\n",
    "    num_stacking_model = 1 #2 # catboost, lgb\n",
    "    preds = 0\n",
    "    # catboost\n",
    "    cat_features = [0,1,2]\n",
    "    pool_test = catboost.Pool(test_df[cols].values, cat_features=cat_features)\n",
    "    for stacking_fold in range(num_stacking_fold):\n",
    "        model = joblib.load(opj(stacking_path, f'cat_fold{stacking_fold}.joblib'))\n",
    "        pred = model.predict(pool_test, prediction_type='Probability')\n",
    "        preds += pred / num_stacking_fold / num_stacking_model * weight / num_fold\n",
    "    # lgb\n",
    "#     cols_lgb = cols.copy()\n",
    "#     le = joblib.load(opj(stacking_path,'label_encoder.joblib'))\n",
    "#     test_df['discourse_type_label'] = le.transform(test_df['discourse_type'])\n",
    "#     test_df['discourse_type_previous_label'] = le.transform(test_df['discourse_type_previous'])\n",
    "#     test_df['discourse_type_next_label'] = le.transform(test_df['discourse_type_next'])\n",
    "#     cols_lgb[0] = 'discourse_type_label'\n",
    "#     cols_lgb[1] = 'discourse_type_previous_label'\n",
    "#     cols_lgb[2] = 'discourse_type_next_label'\n",
    "#     for stacking_fold in range(num_stacking_fold):\n",
    "#         model = joblib.load(opj(stacking_path, f'lgb_fold{stacking_fold}.joblib'))\n",
    "#         pred = model.predict_proba(test_df[cols_lgb].values)\n",
    "#         preds += pred / num_stacking_fold / num_stacking_model * weight / num_fold\n",
    "\n",
    "    test_df[f'Ineffective_{i_model}_{fold}'] = preds[:,0] \n",
    "    test_df[f'Adequate_{i_model}_{fold}'] = preds[:,1]\n",
    "    test_df[f'Effective_{i_model}_{fold}'] = preds[:,2]\n",
    "    \n",
    "    return test_df[['discourse_id',f'Ineffective_{i_model}_{fold}',f'Adequate_{i_model}_{fold}',f'Effective_{i_model}_{fold}']]\n",
    "\n",
    "\n",
    "def convert(_test_df, i_model, fold, num_fold, weight):\n",
    "    test_df = _test_df.copy()\n",
    "    cols = ['Ineffective','Adequate','Effective']\n",
    "    preds = test_df[cols].values\n",
    "    \n",
    "    test_df[f'Ineffective_{i_model}_{fold}'] = preds[:,0] * weight / num_fold\n",
    "    test_df[f'Adequate_{i_model}_{fold}'] = preds[:,1] * weight / num_fold\n",
    "    test_df[f'Effective_{i_model}_{fold}'] = preds[:,2] * weight / num_fold\n",
    "    \n",
    "    return test_df[['discourse_id',f'Ineffective_{i_model}_{fold}',f'Adequate_{i_model}_{fold}',f'Effective_{i_model}_{fold}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a817c1cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:25:05.442917Z",
     "iopub.status.busy": "2022-08-22T03:25:05.442625Z",
     "iopub.status.idle": "2022-08-22T03:25:07.807641Z",
     "shell.execute_reply": "2022-08-22T03:25:07.806673Z"
    },
    "papermill": {
     "duration": 2.38168,
     "end_time": "2022-08-22T03:25:07.809996",
     "exception": false,
     "start_time": "2022-08-22T03:25:05.428316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613\n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  \n",
       "0         0.000223      0.014402       0.032731  \n",
       "1         0.001477      0.040517       0.005362  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  \n",
       "0      0.015682       0.031284  \n",
       "1      0.039686       0.006861  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>Ineffective_0_3</th>\n",
       "      <th>Adequate_0_3</th>\n",
       "      <th>Effective_0_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.039366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>0.014123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  Ineffective_0_3  Adequate_0_3  Effective_0_3  \n",
       "0      0.015682       0.031284         0.000083      0.007907       0.039366  \n",
       "1      0.039686       0.006861         0.000807      0.032426       0.014123  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>Ineffective_0_3</th>\n",
       "      <th>Adequate_0_3</th>\n",
       "      <th>Effective_0_3</th>\n",
       "      <th>Ineffective_0_4</th>\n",
       "      <th>Adequate_0_4</th>\n",
       "      <th>Effective_0_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.039366</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.035898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.034773</td>\n",
       "      <td>0.011773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  Ineffective_0_3  Adequate_0_3  Effective_0_3  \\\n",
       "0      0.015682       0.031284         0.000083      0.007907       0.039366   \n",
       "1      0.039686       0.006861         0.000807      0.032426       0.014123   \n",
       "\n",
       "   Ineffective_0_4  Adequate_0_4  Effective_0_4  \n",
       "0         0.000106      0.011352       0.035898  \n",
       "1         0.000810      0.034773       0.011773  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>Ineffective_0_3</th>\n",
       "      <th>Adequate_0_3</th>\n",
       "      <th>Effective_0_3</th>\n",
       "      <th>Ineffective_0_4</th>\n",
       "      <th>Adequate_0_4</th>\n",
       "      <th>Effective_0_4</th>\n",
       "      <th>Ineffective_1_0</th>\n",
       "      <th>Adequate_1_0</th>\n",
       "      <th>Effective_1_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.039366</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.035898</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.069675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.032426</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.034773</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.055048</td>\n",
       "      <td>0.028243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  Ineffective_0_3  Adequate_0_3  Effective_0_3  \\\n",
       "0      0.015682       0.031284         0.000083      0.007907       0.039366   \n",
       "1      0.039686       0.006861         0.000807      0.032426       0.014123   \n",
       "\n",
       "   Ineffective_0_4  Adequate_0_4  Effective_0_4  Ineffective_1_0  \\\n",
       "0         0.000106      0.011352       0.035898         0.000326   \n",
       "1         0.000810      0.034773       0.011773         0.001181   \n",
       "\n",
       "   Adequate_1_0  Effective_1_0  \n",
       "0      0.014470       0.069675  \n",
       "1      0.055048       0.028243  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_0_3</th>\n",
       "      <th>Ineffective_0_4</th>\n",
       "      <th>Adequate_0_4</th>\n",
       "      <th>Effective_0_4</th>\n",
       "      <th>Ineffective_1_0</th>\n",
       "      <th>Adequate_1_0</th>\n",
       "      <th>Effective_1_0</th>\n",
       "      <th>Ineffective_1_1</th>\n",
       "      <th>Adequate_1_1</th>\n",
       "      <th>Effective_1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039366</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.035898</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.069675</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.059304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.034773</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.055048</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.063098</td>\n",
       "      <td>0.018864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_0_3  Ineffective_0_4  \\\n",
       "0      0.015682       0.031284  ...       0.039366         0.000106   \n",
       "1      0.039686       0.006861  ...       0.014123         0.000810   \n",
       "\n",
       "   Adequate_0_4  Effective_0_4  Ineffective_1_0  Adequate_1_0  Effective_1_0  \\\n",
       "0      0.011352       0.035898         0.000326      0.014470       0.069675   \n",
       "1      0.034773       0.011773         0.001181      0.055048       0.028243   \n",
       "\n",
       "   Ineffective_1_1  Adequate_1_1  Effective_1_1  \n",
       "0         0.000443      0.024725       0.059304  \n",
       "1         0.002510      0.063098       0.018864  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_0_4</th>\n",
       "      <th>Ineffective_1_0</th>\n",
       "      <th>Adequate_1_0</th>\n",
       "      <th>Effective_1_0</th>\n",
       "      <th>Ineffective_1_1</th>\n",
       "      <th>Adequate_1_1</th>\n",
       "      <th>Effective_1_1</th>\n",
       "      <th>Ineffective_1_2</th>\n",
       "      <th>Adequate_1_2</th>\n",
       "      <th>Effective_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035898</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.069675</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.024519</td>\n",
       "      <td>0.059555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.055048</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.063098</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.066538</td>\n",
       "      <td>0.015292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_0_4  Ineffective_1_0  \\\n",
       "0      0.015682       0.031284  ...       0.035898         0.000326   \n",
       "1      0.039686       0.006861  ...       0.011773         0.001181   \n",
       "\n",
       "   Adequate_1_0  Effective_1_0  Ineffective_1_1  Adequate_1_1  Effective_1_1  \\\n",
       "0      0.014470       0.069675         0.000443      0.024725       0.059304   \n",
       "1      0.055048       0.028243         0.002510      0.063098       0.018864   \n",
       "\n",
       "   Ineffective_1_2  Adequate_1_2  Effective_1_2  \n",
       "0         0.000399      0.024519       0.059555  \n",
       "1         0.002642      0.066538       0.015292  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_1_0</th>\n",
       "      <th>Ineffective_1_1</th>\n",
       "      <th>Adequate_1_1</th>\n",
       "      <th>Effective_1_1</th>\n",
       "      <th>Ineffective_1_2</th>\n",
       "      <th>Adequate_1_2</th>\n",
       "      <th>Effective_1_2</th>\n",
       "      <th>Ineffective_1_3</th>\n",
       "      <th>Adequate_1_3</th>\n",
       "      <th>Effective_1_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069675</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.024519</td>\n",
       "      <td>0.059555</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.065740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.063098</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.066538</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.060097</td>\n",
       "      <td>0.023114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_1_0  Ineffective_1_1  \\\n",
       "0      0.015682       0.031284  ...       0.069675         0.000443   \n",
       "1      0.039686       0.006861  ...       0.028243         0.002510   \n",
       "\n",
       "   Adequate_1_1  Effective_1_1  Ineffective_1_2  Adequate_1_2  Effective_1_2  \\\n",
       "0      0.024725       0.059304         0.000399      0.024519       0.059555   \n",
       "1      0.063098       0.018864         0.002642      0.066538       0.015292   \n",
       "\n",
       "   Ineffective_1_3  Adequate_1_3  Effective_1_3  \n",
       "0         0.000191      0.018540       0.065740  \n",
       "1         0.001261      0.060097       0.023114  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_1_1</th>\n",
       "      <th>Ineffective_1_2</th>\n",
       "      <th>Adequate_1_2</th>\n",
       "      <th>Effective_1_2</th>\n",
       "      <th>Ineffective_1_3</th>\n",
       "      <th>Adequate_1_3</th>\n",
       "      <th>Effective_1_3</th>\n",
       "      <th>Ineffective_1_4</th>\n",
       "      <th>Adequate_1_4</th>\n",
       "      <th>Effective_1_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.024519</td>\n",
       "      <td>0.059555</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.021856</td>\n",
       "      <td>0.062332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.066538</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.060097</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>0.024181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_1_1  Ineffective_1_2  \\\n",
       "0      0.015682       0.031284  ...       0.059304         0.000399   \n",
       "1      0.039686       0.006861  ...       0.018864         0.002642   \n",
       "\n",
       "   Adequate_1_2  Effective_1_2  Ineffective_1_3  Adequate_1_3  Effective_1_3  \\\n",
       "0      0.024519       0.059555         0.000191      0.018540       0.065740   \n",
       "1      0.066538       0.015292         0.001261      0.060097       0.023114   \n",
       "\n",
       "   Ineffective_1_4  Adequate_1_4  Effective_1_4  \n",
       "0         0.000284      0.021856       0.062332  \n",
       "1         0.001594      0.058697       0.024181  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 5093.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 7096.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_1_2</th>\n",
       "      <th>Ineffective_1_3</th>\n",
       "      <th>Adequate_1_3</th>\n",
       "      <th>Effective_1_3</th>\n",
       "      <th>Ineffective_1_4</th>\n",
       "      <th>Adequate_1_4</th>\n",
       "      <th>Effective_1_4</th>\n",
       "      <th>Ineffective_2_0</th>\n",
       "      <th>Adequate_2_0</th>\n",
       "      <th>Effective_2_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059555</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.021856</td>\n",
       "      <td>0.062332</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.018769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.060097</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>0.024181</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.009388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_1_2  Ineffective_1_3  \\\n",
       "0      0.015682       0.031284  ...       0.059555         0.000191   \n",
       "1      0.039686       0.006861  ...       0.015292         0.001261   \n",
       "\n",
       "   Adequate_1_3  Effective_1_3  Ineffective_1_4  Adequate_1_4  Effective_1_4  \\\n",
       "0      0.018540       0.065740         0.000284      0.021856       0.062332   \n",
       "1      0.060097       0.023114         0.001594      0.058697       0.024181   \n",
       "\n",
       "   Ineffective_2_0  Adequate_2_0  Effective_2_0  \n",
       "0         0.000579      0.010154       0.018769  \n",
       "1         0.001164      0.018949       0.009388  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 4812.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10394.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_1_3</th>\n",
       "      <th>Ineffective_1_4</th>\n",
       "      <th>Adequate_1_4</th>\n",
       "      <th>Effective_1_4</th>\n",
       "      <th>Ineffective_2_0</th>\n",
       "      <th>Adequate_2_0</th>\n",
       "      <th>Effective_2_0</th>\n",
       "      <th>Ineffective_2_1</th>\n",
       "      <th>Adequate_2_1</th>\n",
       "      <th>Effective_2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.021856</td>\n",
       "      <td>0.062332</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.012886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>0.024181</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_1_3  Ineffective_1_4  \\\n",
       "0      0.015682       0.031284  ...       0.065740         0.000284   \n",
       "1      0.039686       0.006861  ...       0.023114         0.001594   \n",
       "\n",
       "   Adequate_1_4  Effective_1_4  Ineffective_2_0  Adequate_2_0  Effective_2_0  \\\n",
       "0      0.021856       0.062332         0.000579      0.010154       0.018769   \n",
       "1      0.058697       0.024181         0.001164      0.018949       0.009388   \n",
       "\n",
       "   Ineffective_2_1  Adequate_2_1  Effective_2_1  \n",
       "0         0.000714      0.015902       0.012886  \n",
       "1         0.001223      0.024409       0.003870  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 5105.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 9347.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_1_4</th>\n",
       "      <th>Ineffective_2_0</th>\n",
       "      <th>Adequate_2_0</th>\n",
       "      <th>Effective_2_0</th>\n",
       "      <th>Ineffective_2_1</th>\n",
       "      <th>Adequate_2_1</th>\n",
       "      <th>Effective_2_1</th>\n",
       "      <th>Ineffective_2_2</th>\n",
       "      <th>Adequate_2_2</th>\n",
       "      <th>Effective_2_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062332</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.018127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024181</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.007173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_1_4  Ineffective_2_0  \\\n",
       "0      0.015682       0.031284  ...       0.062332         0.000579   \n",
       "1      0.039686       0.006861  ...       0.024181         0.001164   \n",
       "\n",
       "   Adequate_2_0  Effective_2_0  Ineffective_2_1  Adequate_2_1  Effective_2_1  \\\n",
       "0      0.010154       0.018769         0.000714      0.015902       0.012886   \n",
       "1      0.018949       0.009388         0.001223      0.024409       0.003870   \n",
       "\n",
       "   Ineffective_2_2  Adequate_2_2  Effective_2_2  \n",
       "0         0.000491      0.010883       0.018127  \n",
       "1         0.000816      0.021512       0.007173  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 7799.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 14107.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_2_0</th>\n",
       "      <th>Ineffective_2_1</th>\n",
       "      <th>Adequate_2_1</th>\n",
       "      <th>Effective_2_1</th>\n",
       "      <th>Ineffective_2_2</th>\n",
       "      <th>Adequate_2_2</th>\n",
       "      <th>Effective_2_2</th>\n",
       "      <th>Ineffective_2_3</th>\n",
       "      <th>Adequate_2_3</th>\n",
       "      <th>Effective_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>0.020269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.020638</td>\n",
       "      <td>0.007961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_2_0  Ineffective_2_1  \\\n",
       "0      0.015682       0.031284  ...       0.018769         0.000714   \n",
       "1      0.039686       0.006861  ...       0.009388         0.001223   \n",
       "\n",
       "   Adequate_2_1  Effective_2_1  Ineffective_2_2  Adequate_2_2  Effective_2_2  \\\n",
       "0      0.015902       0.012886         0.000491      0.010883       0.018127   \n",
       "1      0.024409       0.003870         0.000816      0.021512       0.007173   \n",
       "\n",
       "   Ineffective_2_3  Adequate_2_3  Effective_2_3  \n",
       "0         0.000398      0.008834       0.020269  \n",
       "1         0.000902      0.020638       0.007961  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 8156.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 11818.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_2_1</th>\n",
       "      <th>Ineffective_2_2</th>\n",
       "      <th>Adequate_2_2</th>\n",
       "      <th>Effective_2_2</th>\n",
       "      <th>Ineffective_2_3</th>\n",
       "      <th>Adequate_2_3</th>\n",
       "      <th>Effective_2_3</th>\n",
       "      <th>Ineffective_2_4</th>\n",
       "      <th>Adequate_2_4</th>\n",
       "      <th>Effective_2_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>0.020269</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.020990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.020638</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.010103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_2_1  Ineffective_2_2  \\\n",
       "0      0.015682       0.031284  ...       0.012886         0.000491   \n",
       "1      0.039686       0.006861  ...       0.003870         0.000816   \n",
       "\n",
       "   Adequate_2_2  Effective_2_2  Ineffective_2_3  Adequate_2_3  Effective_2_3  \\\n",
       "0      0.010883       0.018127         0.000398      0.008834       0.020269   \n",
       "1      0.021512       0.007173         0.000902      0.020638       0.007961   \n",
       "\n",
       "   Ineffective_2_4  Adequate_2_4  Effective_2_4  \n",
       "0         0.000422      0.008089       0.020990  \n",
       "1         0.000890      0.018509       0.010103  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 8092.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16892.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_2_2</th>\n",
       "      <th>Ineffective_2_3</th>\n",
       "      <th>Adequate_2_3</th>\n",
       "      <th>Effective_2_3</th>\n",
       "      <th>Ineffective_2_4</th>\n",
       "      <th>Adequate_2_4</th>\n",
       "      <th>Effective_2_4</th>\n",
       "      <th>Ineffective_3_0</th>\n",
       "      <th>Adequate_3_0</th>\n",
       "      <th>Effective_3_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>0.020269</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.020990</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.026998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.020638</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.026651</td>\n",
       "      <td>0.011024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_2_2  Ineffective_2_3  \\\n",
       "0      0.015682       0.031284  ...       0.018127         0.000398   \n",
       "1      0.039686       0.006861  ...       0.007173         0.000902   \n",
       "\n",
       "   Adequate_2_3  Effective_2_3  Ineffective_2_4  Adequate_2_4  Effective_2_4  \\\n",
       "0      0.008834       0.020269         0.000422      0.008089       0.020990   \n",
       "1      0.020638       0.007961         0.000890      0.018509       0.010103   \n",
       "\n",
       "   Ineffective_3_0  Adequate_3_0  Effective_3_0  \n",
       "0         0.000420      0.011252       0.026998  \n",
       "1         0.000996      0.026651       0.011024  \n",
       "\n",
       "[2 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 4949.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10353.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_2_3</th>\n",
       "      <th>Ineffective_2_4</th>\n",
       "      <th>Adequate_2_4</th>\n",
       "      <th>Effective_2_4</th>\n",
       "      <th>Ineffective_3_0</th>\n",
       "      <th>Adequate_3_0</th>\n",
       "      <th>Effective_3_0</th>\n",
       "      <th>Ineffective_3_1</th>\n",
       "      <th>Adequate_3_1</th>\n",
       "      <th>Effective_3_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020269</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.020990</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.018197</td>\n",
       "      <td>0.019816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.026651</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.008222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_2_3  Ineffective_2_4  \\\n",
       "0      0.015682       0.031284  ...       0.020269         0.000422   \n",
       "1      0.039686       0.006861  ...       0.007961         0.000890   \n",
       "\n",
       "   Adequate_2_4  Effective_2_4  Ineffective_3_0  Adequate_3_0  Effective_3_0  \\\n",
       "0      0.008089       0.020990         0.000420      0.011252       0.026998   \n",
       "1      0.018509       0.010103         0.000996      0.026651       0.011024   \n",
       "\n",
       "   Ineffective_3_1  Adequate_3_1  Effective_3_1  \n",
       "0         0.000657      0.018197       0.019816  \n",
       "1         0.001802      0.028646       0.008222  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 6271.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape = "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13851.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_2_4</th>\n",
       "      <th>Ineffective_3_0</th>\n",
       "      <th>Adequate_3_0</th>\n",
       "      <th>Effective_3_0</th>\n",
       "      <th>Ineffective_3_1</th>\n",
       "      <th>Adequate_3_1</th>\n",
       "      <th>Effective_3_1</th>\n",
       "      <th>Ineffective_3_2</th>\n",
       "      <th>Adequate_3_2</th>\n",
       "      <th>Effective_3_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020990</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.018197</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.023286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.026651</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.027585</td>\n",
       "      <td>0.009819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_2_4  Ineffective_3_0  \\\n",
       "0      0.015682       0.031284  ...       0.020990         0.000420   \n",
       "1      0.039686       0.006861  ...       0.010103         0.000996   \n",
       "\n",
       "   Adequate_3_0  Effective_3_0  Ineffective_3_1  Adequate_3_1  Effective_3_1  \\\n",
       "0      0.011252       0.026998         0.000657      0.018197       0.019816   \n",
       "1      0.026651       0.011024         0.001802      0.028646       0.008222   \n",
       "\n",
       "   Ineffective_3_2  Adequate_3_2  Effective_3_2  \n",
       "0         0.000588      0.014796       0.023286  \n",
       "1         0.001266      0.027585       0.009819  \n",
       "\n",
       "[2 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 5154.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 9549.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_3_0</th>\n",
       "      <th>Ineffective_3_1</th>\n",
       "      <th>Adequate_3_1</th>\n",
       "      <th>Effective_3_1</th>\n",
       "      <th>Ineffective_3_2</th>\n",
       "      <th>Adequate_3_2</th>\n",
       "      <th>Effective_3_2</th>\n",
       "      <th>Ineffective_3_3</th>\n",
       "      <th>Adequate_3_3</th>\n",
       "      <th>Effective_3_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.018197</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.023136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.027585</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.010060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_3_0  Ineffective_3_1  \\\n",
       "0      0.015682       0.031284  ...       0.026998         0.000657   \n",
       "1      0.039686       0.006861  ...       0.011024         0.001802   \n",
       "\n",
       "   Adequate_3_1  Effective_3_1  Ineffective_3_2  Adequate_3_2  Effective_3_2  \\\n",
       "0      0.018197       0.019816         0.000588      0.014796       0.023286   \n",
       "1      0.028646       0.008222         0.001266      0.027585       0.009819   \n",
       "\n",
       "   Ineffective_3_3  Adequate_3_3  Effective_3_3  \n",
       "0         0.000601      0.014933       0.023136  \n",
       "1         0.001798      0.026813       0.010060  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold =  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 6535.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_features.shape =  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 11444.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape =  (10, 40)\n",
      "cols =  ['discourse_type', 'discourse_type_previous', 'discourse_type_next', 'Ineffective', 'Adequate', 'Effective', 'Ineffective_previous', 'Adequate_previous', 'Effective_previous', 'Ineffective_next', 'Adequate_next', 'Effective_next', 'mean_Ineffective', 'mean_Adequate', 'mean_Effective', 'std_Ineffective', 'std_Adequate', 'std_Effective', 'discourse_count', 'Claim_count', 'Evidence_count', 'Concluding Statement_count', 'Lead_count', 'Position_count', 'Counterclaim_count', 'Rebuttal_count', 'instability_0', 'instability_1', 'instability_2', 'instability_3', 'begin_0', 'begin_1', 'begin_2', 'end_0', 'end_1', 'end_2', 'len']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>Ineffective_0_2</th>\n",
       "      <th>Adequate_0_2</th>\n",
       "      <th>Effective_0_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_3_1</th>\n",
       "      <th>Ineffective_3_2</th>\n",
       "      <th>Adequate_3_2</th>\n",
       "      <th>Effective_3_2</th>\n",
       "      <th>Ineffective_3_3</th>\n",
       "      <th>Adequate_3_3</th>\n",
       "      <th>Effective_3_3</th>\n",
       "      <th>Ineffective_3_4</th>\n",
       "      <th>Adequate_3_4</th>\n",
       "      <th>Effective_3_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.028943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.039686</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.027585</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.025682</td>\n",
       "      <td>0.012014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective_0_0  Adequate_0_0  Effective_0_0  \\\n",
       "0  a261b6e14276         0.000159      0.010583       0.036613   \n",
       "1  5a88900e7dc1         0.000719      0.037760       0.008878   \n",
       "\n",
       "   Ineffective_0_1  Adequate_0_1  Effective_0_1  Ineffective_0_2  \\\n",
       "0         0.000223      0.014402       0.032731         0.000390   \n",
       "1         0.001477      0.040517       0.005362         0.000809   \n",
       "\n",
       "   Adequate_0_2  Effective_0_2  ...  Effective_3_1  Ineffective_3_2  \\\n",
       "0      0.015682       0.031284  ...       0.019816         0.000588   \n",
       "1      0.039686       0.006861  ...       0.008222         0.001266   \n",
       "\n",
       "   Adequate_3_2  Effective_3_2  Ineffective_3_3  Adequate_3_3  Effective_3_3  \\\n",
       "0      0.014796       0.023286         0.000601      0.014933       0.023136   \n",
       "1      0.027585       0.009819         0.001798      0.026813       0.010060   \n",
       "\n",
       "   Ineffective_3_4  Adequate_3_4  Effective_3_4  \n",
       "0         0.000431      0.009296       0.028943  \n",
       "1         0.000974      0.025682       0.012014  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if IS_PRIVATE:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #assert len(model_list)==1\n",
    "    \n",
    "    pred_df = None\n",
    "    for i_model,(model,num_fold,w,stacking_path,num_stacking_fold) in enumerate(model_list):\n",
    "        for fold in range(num_fold):\n",
    "            try:\n",
    "                tmp_df = pd.read_csv(f'raw_pred_{model}_fold{fold}.csv')\n",
    "                print('fold = ', fold)\n",
    "            except:\n",
    "                tmp_df = pd.read_csv(f'raw_pred_{model}_seed{(fold+1)*100}.csv')\n",
    "                print('seed = ', (fold+1)*100)\n",
    "            \n",
    "            if stacking_path!='none':\n",
    "                # based on https://stackoverflow.com/questions/45704999/how-to-convert-vector-wrapped-as-string-to-numpy-array-in-pandas-dataframe\n",
    "                tmp_df['prob_seq'] = tmp_df['prob_seq'].apply(lambda x:np.fromstring(x.replace('\\n','')\n",
    "                                                                                       .replace('[','')\n",
    "                                                                                       .replace(']','')\n",
    "                                                                                       .replace('  ',' '), sep=' '))\n",
    "                prob_seqs = [tmp_df['prob_seq'].values[i].reshape(-1,3) for i in range(len(tmp_df))]\n",
    "\n",
    "                tmp_df = tmp_df.merge(test_df[['essay_id','discourse_id','discourse_type']], on='discourse_id', how='left')\n",
    "                tmp_df = stacking(tmp_df, prob_seqs, stacking_path, num_stacking_fold, i_model, fold, num_fold, \n",
    "                                  weight=w, use_prob_seq=True)\n",
    "            else:\n",
    "                tmp_df = convert(tmp_df, i_model, fold, num_fold, weight=w)\n",
    "            \n",
    "            if pred_df is None:\n",
    "                pred_df = tmp_df.copy()\n",
    "            else:\n",
    "                pred_df = pred_df.merge(tmp_df, on='discourse_id', how='left')\n",
    "            display(pred_df.head(2))\n",
    "        \n",
    "    # sum all weighted predictions\n",
    "    for col_name in ['Ineffective','Adequate','Effective']:\n",
    "        cols = []\n",
    "        for i_model,(_,num_fold,_,_,_) in enumerate(model_list):\n",
    "            for fold in range(num_fold):\n",
    "                cols.append(f'{col_name}_{i_model}_{fold}')\n",
    "        #pred_df[col_name] = pred_df[cols].mean(axis=1)\n",
    "        pred_df[col_name] = pred_df[cols].sum(axis=1)\n",
    "    \n",
    "    test_df = test_df.merge(pred_df, on='discourse_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "076df13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:25:07.857048Z",
     "iopub.status.busy": "2022-08-22T03:25:07.856250Z",
     "iopub.status.idle": "2022-08-22T03:25:07.878113Z",
     "shell.execute_reply": "2022-08-22T03:25:07.877198Z"
    },
    "papermill": {
     "duration": 0.046385,
     "end_time": "2022-08-22T03:25:07.880182",
     "exception": false,
     "start_time": "2022-08-22T03:25:07.833797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>Ineffective_0_0</th>\n",
       "      <th>Adequate_0_0</th>\n",
       "      <th>Effective_0_0</th>\n",
       "      <th>Ineffective_0_1</th>\n",
       "      <th>Adequate_0_1</th>\n",
       "      <th>Effective_0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_3_2</th>\n",
       "      <th>Ineffective_3_3</th>\n",
       "      <th>Adequate_3_3</th>\n",
       "      <th>Effective_3_3</th>\n",
       "      <th>Ineffective_3_4</th>\n",
       "      <th>Adequate_3_4</th>\n",
       "      <th>Effective_3_4</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.014402</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.286373</td>\n",
       "      <td>0.705720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.037760</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.025682</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.025642</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.246325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>0.023887</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.026944</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.059154</td>\n",
       "      <td>0.472154</td>\n",
       "      <td>0.468692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.023307</td>\n",
       "      <td>0.020917</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.024893</td>\n",
       "      <td>0.015136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.460075</td>\n",
       "      <td>0.418250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.025378</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.031177</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013105</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.021149</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.142441</td>\n",
       "      <td>0.526228</td>\n",
       "      <td>0.331331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  a261b6e14276  D72CB1C11673   \n",
       "1  5a88900e7dc1  D72CB1C11673   \n",
       "2  9790d835736b  D72CB1C11673   \n",
       "3  75ce6d68b67b  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Making choices in life can be very difficult. ...           Lead   \n",
       "1  Seeking multiple opinions can help a person ma...       Position   \n",
       "2                     it can decrease stress levels           Claim   \n",
       "3             a great chance to learn something new           Claim   \n",
       "4               can be very helpful and beneficial.           Claim   \n",
       "\n",
       "   Ineffective_0_0  Adequate_0_0  Effective_0_0  Ineffective_0_1  \\\n",
       "0         0.000159      0.010583       0.036613         0.000223   \n",
       "1         0.000719      0.037760       0.008878         0.001477   \n",
       "2         0.000885      0.022584       0.023887         0.002383   \n",
       "3         0.003132      0.023307       0.020917         0.007327   \n",
       "4         0.005233      0.025378       0.016745         0.007383   \n",
       "\n",
       "   Adequate_0_1  Effective_0_1  ...  Effective_3_2  Ineffective_3_3  \\\n",
       "0      0.014402       0.032731  ...       0.023286         0.000601   \n",
       "1      0.040517       0.005362  ...       0.009819         0.001798   \n",
       "2      0.026944       0.018028  ...       0.018636         0.007243   \n",
       "3      0.024893       0.015136  ...       0.017770         0.010174   \n",
       "4      0.031177       0.008796  ...       0.013105         0.008712   \n",
       "\n",
       "   Adequate_3_3  Effective_3_3  Ineffective_3_4  Adequate_3_4  Effective_3_4  \\\n",
       "0      0.014933       0.023136         0.000431      0.009296       0.028943   \n",
       "1      0.026813       0.010060         0.000974      0.025682       0.012014   \n",
       "2      0.019501       0.011926         0.001858      0.018686       0.018127   \n",
       "3      0.018499       0.009997         0.002451      0.018814       0.017406   \n",
       "4      0.021765       0.008194         0.008178      0.021149       0.009343   \n",
       "\n",
       "   Ineffective  Adequate  Effective  \n",
       "0     0.007907  0.286373   0.705720  \n",
       "1     0.025642  0.728033   0.246325  \n",
       "2     0.059154  0.472154   0.468692  \n",
       "3     0.121675  0.460075   0.418250  \n",
       "4     0.142441  0.526228   0.331331  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0262b",
   "metadata": {
    "papermill": {
     "duration": 0.022829,
     "end_time": "2022-08-22T03:25:07.925511",
     "exception": false,
     "start_time": "2022-08-22T03:25:07.902682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d54b68",
   "metadata": {
    "papermill": {
     "duration": 0.021761,
     "end_time": "2022-08-22T03:25:07.968765",
     "exception": false,
     "start_time": "2022-08-22T03:25:07.947004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88cbbc13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T03:25:08.013673Z",
     "iopub.status.busy": "2022-08-22T03:25:08.013196Z",
     "iopub.status.idle": "2022-08-22T03:25:08.033160Z",
     "shell.execute_reply": "2022-08-22T03:25:08.032289Z"
    },
    "papermill": {
     "duration": 0.04471,
     "end_time": "2022-08-22T03:25:08.035290",
     "exception": false,
     "start_time": "2022-08-22T03:25:07.990580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.286373</td>\n",
       "      <td>0.705720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.025642</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.246325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>0.059154</td>\n",
       "      <td>0.472154</td>\n",
       "      <td>0.468692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.460075</td>\n",
       "      <td>0.418250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>0.142441</td>\n",
       "      <td>0.526228</td>\n",
       "      <td>0.331331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2e214524dbe3</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>0.441570</td>\n",
       "      <td>0.543430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84812fc2ab9f</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.397030</td>\n",
       "      <td>0.587612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c668ff840720</td>\n",
       "      <td>0.057248</td>\n",
       "      <td>0.553112</td>\n",
       "      <td>0.389639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739a6d00f44a</td>\n",
       "      <td>0.028278</td>\n",
       "      <td>0.445581</td>\n",
       "      <td>0.526141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcfae2c9a244</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.478019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective  Adequate  Effective\n",
       "0  a261b6e14276     0.007907  0.286373   0.705720\n",
       "1  5a88900e7dc1     0.025642  0.728033   0.246325\n",
       "2  9790d835736b     0.059154  0.472154   0.468692\n",
       "3  75ce6d68b67b     0.121675  0.460075   0.418250\n",
       "4  93578d946723     0.142441  0.526228   0.331331\n",
       "5  2e214524dbe3     0.015001  0.441570   0.543430\n",
       "6  84812fc2ab9f     0.015358  0.397030   0.587612\n",
       "7  c668ff840720     0.057248  0.553112   0.389639\n",
       "8  739a6d00f44a     0.028278  0.445581   0.526141\n",
       "9  bcfae2c9a244     0.012682  0.509299   0.478019"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../input/feedback-prize-effectiveness/sample_submission.csv')\n",
    "#sub_df = test_df.copy()\n",
    "\n",
    "if IS_PRIVATE:\n",
    "    sub_df = pd.merge(sub_df[['discourse_id']], \n",
    "                      test_df[['discourse_id','Ineffective','Adequate','Effective']], \n",
    "                      on='discourse_id', \n",
    "                      how='left')\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b19e6",
   "metadata": {
    "papermill": {
     "duration": 0.021487,
     "end_time": "2022-08-22T03:25:08.079092",
     "exception": false,
     "start_time": "2022-08-22T03:25:08.057605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b8e7c",
   "metadata": {
    "papermill": {
     "duration": 0.021985,
     "end_time": "2022-08-22T03:25:08.122685",
     "exception": false,
     "start_time": "2022-08-22T03:25:08.100700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 895.650739,
   "end_time": "2022-08-22T03:25:10.991925",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-22T03:10:15.341186",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
